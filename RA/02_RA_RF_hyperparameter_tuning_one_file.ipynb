{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from numpy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_variable = 'ACR20'\n",
    "\n",
    "list_n_tree = [10,30,100,300,1000]\n",
    "list_n_max_depth = [2,3,4,5,7,10, None]\n",
    "list_n_min_samples_split = [2,3,4,5]\n",
    "list_n_min_samples_leaf = [1,2,3,4,5]\n",
    "list_iteration = [1,2,3]\n",
    "\n",
    "std_cutoff = 0.05\n",
    "Path(\"./Hyperparameter\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./Hyperparameter/RF\").mkdir(parents=True, exist_ok=True)\n",
    "output_file = './Hyperparameter/RF/performance_of_RF_models.txt'\n",
    "\n",
    "df=pd.read_csv('./Input_data/RA_input.txt', sep='\\t')\n",
    "\n",
    "df=df[df.ACR20 != 3]\n",
    "\n",
    "colnames = df.columns\n",
    "result_column_list = ['newID', 'region', 'BSD', 'DFT1', 'DFT2', 'ACR20', 'ACR50', 'ACR70', 'EULAR']\n",
    "x_colnames_1 = [item for item in colnames if item not in result_column_list] \n",
    "# They are not needed because it means results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df[(df.region!=1) & (df.region != 11)]\n",
    "df_independent = df[(df.region == 1) | (df.region == 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Training dataset\n",
    "\n",
    "df_training_remov_result = df_training[x_colnames_1] # pre-scaled data\n",
    "# Remove variables includes only one value.\n",
    "df_training_remov_novar = df_training_remov_result.loc[:,df_training_remov_result.std() != 0]\n",
    "\n",
    "# Remove variables includes only small variance.\n",
    "pre_scaler = preprocessing.MinMaxScaler()\n",
    "df_training_pre_scaled = pre_scaler.fit_transform(df_training_remov_novar)\n",
    "remain_boolean = df_training_pre_scaled.std(axis=0) >= std_cutoff\n",
    "colnames_remain = df_training_remov_novar.columns[remain_boolean]\n",
    "# colnames_remain will be used for independent data again.\n",
    "\n",
    "data_x_training_bf_scaling = df_training_remov_novar[colnames_remain].to_numpy()\n",
    "data_y_training = df_training[prediction_variable].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Independent dataset\n",
    "\n",
    "data_x_independent_bf_scaling = df_independent[colnames_remain].to_numpy()\n",
    "data_y_independent = df_independent[prediction_variable].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_file)\n",
    "perf_file = open(output_file, 'w')\n",
    "\n",
    "for n_tree in list_n_tree:\n",
    "    for n_max_depth in list_n_max_depth:\n",
    "        for n_min_samples_split in list_n_min_samples_split:\n",
    "            for n_min_samples_leaf in list_n_min_samples_leaf:\n",
    "                for iteration in list_iteration:\n",
    "                    \n",
    "                    print(' '.join([prediction_variable, str(n_tree), str(n_max_depth), str(n_min_samples_split), str(n_min_samples_leaf), str(iteration)]))\n",
    "                        \n",
    "                    seed=random.randint(1,1000)\n",
    "                    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "                    tprs = []\n",
    "                    mean_fpr = np.linspace(0, 1, 100)\n",
    "                    accs = []\n",
    "                    ROC_aucs = []\n",
    "                    f1s = []\n",
    "                    RP_aucs = []\n",
    "\n",
    "                    tprs_ind = []\n",
    "                    accs_ind = []\n",
    "                    ROC_aucs_ind = []\n",
    "                    f1s_ind = []\n",
    "                    RP_aucs_ind = []\n",
    "\n",
    "                    tprs_ind_tscaler = []\n",
    "                    accs_ind_tscaler = []\n",
    "                    ROC_aucs_ind_tscaler = []\n",
    "                    f1s_ind_tscaler = []\n",
    "                    RP_aucs_ind_tscaler = []\n",
    "\n",
    "                    i = 0\n",
    "\n",
    "                    for train, test in cv.split(data_x_training_bf_scaling, data_y_training):\n",
    "\n",
    "                        training_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "                        data_x_training_train = training_scaler.fit_transform(data_x_training_bf_scaling[train])\n",
    "                        data_x_training_test = training_scaler.transform(data_x_training_bf_scaling[test])\n",
    "\n",
    "                        model = RandomForestClassifier(n_estimators=n_tree, max_depth = n_max_depth, \n",
    "                                                       min_samples_split = n_min_samples_split, min_samples_leaf = n_min_samples_leaf)\n",
    "                        model.fit(data_x_training_train, data_y_training[train])\n",
    "\n",
    "                        test_acc = model.score(data_x_training_test, data_y_training[test])\n",
    "                        predictions = model.predict_proba(data_x_training_test)[:,1]\n",
    "\n",
    "                        accs.append(test_acc)\n",
    "\n",
    "                        fpr, tpr, threshold = metrics.roc_curve(data_y_training[test], predictions)\n",
    "                        roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "                        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "                        tprs[-1][0] = 0.0\n",
    "                        ROC_aucs.append(roc_auc)\n",
    "\n",
    "                        precision, recall, thresholds = precision_recall_curve(data_y_training[test], predictions)\n",
    "                        f1 = f1_score(data_y_training[test], predictions.round())\n",
    "                        f1s.append(f1)\n",
    "                        rp_auc = metrics.auc(recall, precision)\n",
    "                        RP_aucs.append(rp_auc)\n",
    "\n",
    "                        # 1st method: independent dataset -> independent scaler\n",
    "\n",
    "                        ind_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "                        data_x_independent = ind_scaler.fit_transform(data_x_independent_bf_scaling)\n",
    "\n",
    "                        test_acc_ind = model.score(data_x_independent, data_y_independent)\n",
    "                        predictions_ind = model.predict_proba(data_x_independent)[:,1]\n",
    "\n",
    "                        accs_ind.append(test_acc_ind)\n",
    "\n",
    "                        fpr_ind, tpr_ind, threshold = metrics.roc_curve(data_y_independent, predictions_ind)\n",
    "                        roc_auc_ind = metrics.auc(fpr_ind, tpr_ind)\n",
    "\n",
    "                        tprs_ind.append(interp(mean_fpr, fpr_ind, tpr_ind))\n",
    "                        tprs_ind[-1][0] = 0.0\n",
    "                        ROC_aucs_ind.append(roc_auc_ind)\n",
    "\n",
    "                        precision_ind, recall_ind, thresholds = precision_recall_curve(data_y_independent, predictions_ind)\n",
    "                        f1_ind = f1_score(data_y_independent, predictions_ind.round())\n",
    "                        f1s_ind.append(f1_ind)\n",
    "                        rp_auc_ind = metrics.auc(recall_ind, precision_ind)\n",
    "                        RP_aucs_ind.append(rp_auc_ind)\n",
    "\n",
    "                        # 2nd method: independent dataset scaling with training scaler\n",
    "\n",
    "                        data_x_independent_tscaler = training_scaler.transform(data_x_independent_bf_scaling)\n",
    "\n",
    "                        test_acc_ind_tscaler = model.score(data_x_independent_tscaler, data_y_independent)\n",
    "                        predictions_ind_tscaler = model.predict_proba(data_x_independent_tscaler)[:,1]\n",
    "\n",
    "                        accs_ind_tscaler.append(test_acc_ind_tscaler)\n",
    "\n",
    "                        fpr_ind_tscaler, tpr_ind_tscaler, threshold = metrics.roc_curve(data_y_independent, predictions_ind_tscaler)\n",
    "                        roc_auc_ind_tscaler = metrics.auc(fpr_ind_tscaler, tpr_ind_tscaler)\n",
    "\n",
    "                        tprs_ind_tscaler.append(interp(mean_fpr, fpr_ind_tscaler, tpr_ind_tscaler))\n",
    "                        tprs_ind_tscaler[-1][0] = 0.0\n",
    "                        ROC_aucs_ind_tscaler.append(roc_auc_ind_tscaler)\n",
    "\n",
    "                        precision_ind_tscaler, recall_ind_tscaler, thresholds = precision_recall_curve(data_y_independent, predictions_ind_tscaler)\n",
    "                        f1_ind_tscaler = f1_score(data_y_independent, predictions_ind_tscaler.round())\n",
    "                        f1s_ind_tscaler.append(f1_ind_tscaler)\n",
    "                        rp_auc_ind_tscaler = metrics.auc(recall_ind_tscaler, precision_ind_tscaler)\n",
    "                        RP_aucs_ind_tscaler.append(rp_auc_ind_tscaler)\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "                    mean_tpr = np.mean(tprs, axis=0)\n",
    "                    mean_tpr[-1] = 1.0\n",
    "                    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "                    std_auc = np.std(ROC_aucs)\n",
    "\n",
    "                    mean_tpr_ind = np.mean(tprs_ind, axis=0)\n",
    "                    mean_tpr_ind[-1] = 1.0\n",
    "                    mean_auc_ind = metrics.auc(mean_fpr, mean_tpr_ind)\n",
    "                    std_auc_ind = np.std(ROC_aucs_ind)\n",
    "\n",
    "                    mean_tpr_ind_tscaler = np.mean(tprs_ind_tscaler, axis=0)\n",
    "                    mean_tpr_ind_tscaler[-1] = 1.0\n",
    "                    mean_auc_ind_tscaler = metrics.auc(mean_fpr, mean_tpr_ind_tscaler)\n",
    "                    std_auc_ind_tscaler = np.std(ROC_aucs_ind_tscaler)\n",
    "\n",
    "                    perf_file.write('\\t'.join([str(seed), str(n_tree), str(n_max_depth), str(n_min_samples_split), \n",
    "                                              str(n_min_samples_leaf), str(iteration), prediction_variable]) + '\\t' + \n",
    "                                    '\\t'.join([str(sum(accs) / 3), '\\t'.join(str(x) for x in accs), \n",
    "                                               str(mean_auc), '\\t'.join(str(x) for x in ROC_aucs),\n",
    "                                               str(sum(f1s)/3), '\\t'.join(str(x) for x in f1s),\n",
    "                                               str(sum(RP_aucs) / 3), '\\t'.join(str(x) for x in RP_aucs),\n",
    "                                               str(sum(accs_ind) / 3), '\\t'.join(str(x) for x in accs_ind), \n",
    "                                               str(mean_auc_ind), '\\t'.join(str(x) for x in ROC_aucs_ind),\n",
    "                                               str(sum(f1s_ind)/3), '\\t'.join(str(x) for x in f1s_ind),\n",
    "                                               str(sum(RP_aucs_ind) / 3), '\\t'.join(str(x) for x in RP_aucs_ind),\n",
    "                                               str(sum(accs_ind_tscaler) / 3), '\\t'.join(str(x) for x in accs_ind_tscaler), \n",
    "                                               str(mean_auc_ind_tscaler), '\\t'.join(str(x) for x in ROC_aucs_ind_tscaler),\n",
    "                                               str(sum(f1s_ind_tscaler)/3), '\\t'.join(str(x) for x in f1s_ind_tscaler),\n",
    "                                               str(sum(RP_aucs_ind_tscaler) / 3), '\\t'.join(str(x) for x in RP_aucs_ind_tscaler)]) + '\\n')\n",
    "                \n",
    "perf_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
