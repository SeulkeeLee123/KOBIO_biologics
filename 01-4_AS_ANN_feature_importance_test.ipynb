{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import backend as K\n",
    "# import keras\n",
    "# from keras import backend as K\n",
    "# from keras.models import load_model\n",
    "#import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_seed = [111,63,682]\n",
    "\n",
    "prediction_variable = 'ASAS20'\n",
    "\n",
    "n_nodes = 50\n",
    "n_layers = 1\n",
    "lr = '3e-05'\n",
    "n_batch = 10\n",
    "n_epochs = 200\n",
    "\n",
    "std_cutoff = 0.05\n",
    "\n",
    "df=pd.read_csv('./AS_dataframe_initial_fu_20210208_naiveusers.txt', sep='\\t')\n",
    "\n",
    "if prediction_variable == 'DFT1':\n",
    "    df = df[df.DFT1 != 2]\n",
    "\n",
    "if prediction_variable == 'ASAS20':\n",
    "    df=df[df.ASAS20 != 3]\n",
    "    \n",
    "if prediction_variable == 'ASAS40':\n",
    "    df=df[df.ASAS40 != 3]\n",
    "\n",
    "colnames = df.columns\n",
    "result_column_list = ['newID', 'region', 'BSD', 'DFT1', 'DFT2', 'ASDAS1', 'ASDAS2', 'ASAS20', 'ASAS40']\n",
    "x_colnames_1 = [item for item in colnames if item not in result_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df[(df.region!=2) & (df.region != 11) & (df.region != 21) & (df.region != 3) & (df.region != 24)]\n",
    "#df_independent = df[(df.region == 2) | (df.region == 11) | (df.region == 21) | (df.region == 3) | (df.region == 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Training dataset\n",
    "\n",
    "df_training_remov_result = df_training[x_colnames_1] # pre-scaled data\n",
    "# Remove variables includes only one value.\n",
    "df_training_remov_novar = df_training_remov_result.loc[:,df_training_remov_result.std() != 0]\n",
    "\n",
    "# Remove variables includes only small variance.\n",
    "pre_scaler = preprocessing.MinMaxScaler()\n",
    "df_training_pre_scaled = pre_scaler.fit_transform(df_training_remov_novar)\n",
    "remain_boolean = df_training_pre_scaled.std(axis=0) >= std_cutoff\n",
    "colnames_remain = df_training_remov_novar.columns[remain_boolean]\n",
    "# colnames_remain will be used for independent data again.\n",
    "\n",
    "data_x_training_bf_scaling = df_training_remov_novar[colnames_remain].to_numpy()\n",
    "data_y_training = df_training[prediction_variable].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = defaultdict(list)\n",
    "dict_train = {}\n",
    "dict_test = {}\n",
    "\n",
    "seed = list_seed[0]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "    \n",
    "i = 0\n",
    "\n",
    "for train, test in cv.split(data_x_training_bf_scaling, data_y_training):\n",
    "    \n",
    "    dict_train[i] = train\n",
    "    dict_test[i] = test\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.67878294]\n",
      " [0.69229436]\n",
      " [0.7760116 ]\n",
      " [0.51582617]\n",
      " [0.5941107 ]\n",
      " [0.68574923]\n",
      " [0.8127461 ]\n",
      " [0.7514208 ]\n",
      " [0.69298214]\n",
      " [0.774083  ]\n",
      " [0.6435938 ]\n",
      " [0.6407733 ]\n",
      " [0.7373961 ]\n",
      " [0.82077324]\n",
      " [0.67483884]\n",
      " [0.6936736 ]\n",
      " [0.77810824]\n",
      " [0.5690722 ]\n",
      " [0.6745034 ]\n",
      " [0.56853783]\n",
      " [0.70716417]\n",
      " [0.815048  ]\n",
      " [0.6608246 ]\n",
      " [0.7399424 ]\n",
      " [0.63365066]\n",
      " [0.78460693]\n",
      " [0.64714146]\n",
      " [0.78861415]\n",
      " [0.69726205]\n",
      " [0.67867213]\n",
      " [0.6360269 ]\n",
      " [0.78892004]\n",
      " [0.7035413 ]\n",
      " [0.5266394 ]\n",
      " [0.81089544]\n",
      " [0.49124172]\n",
      " [0.64064807]\n",
      " [0.7280065 ]\n",
      " [0.71272546]\n",
      " [0.71678895]\n",
      " [0.73877645]\n",
      " [0.63661623]\n",
      " [0.5741825 ]\n",
      " [0.6703152 ]\n",
      " [0.73625416]\n",
      " [0.6823666 ]\n",
      " [0.5333111 ]\n",
      " [0.7050467 ]\n",
      " [0.7098554 ]\n",
      " [0.7156087 ]\n",
      " [0.6833698 ]\n",
      " [0.68079734]\n",
      " [0.71286976]\n",
      " [0.4973319 ]\n",
      " [0.8343092 ]\n",
      " [0.7722332 ]\n",
      " [0.6477176 ]\n",
      " [0.6522367 ]\n",
      " [0.83344156]\n",
      " [0.42123708]\n",
      " [0.6393426 ]\n",
      " [0.595451  ]\n",
      " [0.61703455]\n",
      " [0.81071466]\n",
      " [0.65008384]\n",
      " [0.66321534]\n",
      " [0.80493224]\n",
      " [0.6666335 ]\n",
      " [0.5928909 ]\n",
      " [0.78623676]\n",
      " [0.24094316]\n",
      " [0.5202454 ]\n",
      " [0.5805896 ]\n",
      " [0.5716463 ]\n",
      " [0.70924366]\n",
      " [0.6968961 ]\n",
      " [0.7544563 ]\n",
      " [0.65161115]\n",
      " [0.5285969 ]\n",
      " [0.78915334]\n",
      " [0.6473372 ]\n",
      " [0.7051418 ]\n",
      " [0.6312695 ]\n",
      " [0.65905243]\n",
      " [0.5340217 ]\n",
      " [0.4343736 ]\n",
      " [0.47618064]\n",
      " [0.5772404 ]\n",
      " [0.5706618 ]\n",
      " [0.6538308 ]\n",
      " [0.5458864 ]\n",
      " [0.39847603]\n",
      " [0.66731644]\n",
      " [0.7458112 ]\n",
      " [0.77680266]\n",
      " [0.7297158 ]\n",
      " [0.6665955 ]\n",
      " [0.77743024]\n",
      " [0.7357695 ]\n",
      " [0.75323474]\n",
      " [0.5236133 ]\n",
      " [0.61522436]\n",
      " [0.4109162 ]\n",
      " [0.76071835]\n",
      " [0.8503602 ]\n",
      " [0.70264727]\n",
      " [0.4183003 ]\n",
      " [0.64327633]\n",
      " [0.602958  ]\n",
      " [0.77455336]\n",
      " [0.715771  ]\n",
      " [0.45980516]\n",
      " [0.7926706 ]\n",
      " [0.6558045 ]\n",
      " [0.83155274]\n",
      " [0.5581221 ]\n",
      " [0.5441459 ]\n",
      " [0.64553916]\n",
      " [0.6925442 ]\n",
      " [0.73971826]\n",
      " [0.67339677]\n",
      " [0.69618654]\n",
      " [0.67758286]\n",
      " [0.6989001 ]\n",
      " [0.6833053 ]\n",
      " [0.6043583 ]\n",
      " [0.56045413]\n",
      " [0.69201493]\n",
      " [0.5609425 ]\n",
      " [0.6147463 ]\n",
      " [0.5829593 ]\n",
      " [0.83613646]\n",
      " [0.7038393 ]\n",
      " [0.60388434]\n",
      " [0.6334499 ]\n",
      " [0.6120578 ]\n",
      " [0.8074009 ]\n",
      " [0.62116534]\n",
      " [0.7022233 ]\n",
      " [0.74201506]\n",
      " [0.6517221 ]\n",
      " [0.79254556]\n",
      " [0.67135423]\n",
      " [0.5686545 ]\n",
      " [0.68674445]\n",
      " [0.68418586]\n",
      " [0.5261829 ]\n",
      " [0.7373538 ]\n",
      " [0.7343229 ]\n",
      " [0.6768877 ]\n",
      " [0.5329131 ]\n",
      " [0.58823025]\n",
      " [0.57273155]\n",
      " [0.6594121 ]\n",
      " [0.4639072 ]\n",
      " [0.46814308]\n",
      " [0.7937717 ]\n",
      " [0.6894934 ]\n",
      " [0.6186458 ]\n",
      " [0.54788977]\n",
      " [0.57890743]\n",
      " [0.5984809 ]\n",
      " [0.78972304]\n",
      " [0.6840528 ]\n",
      " [0.7134013 ]\n",
      " [0.6040222 ]\n",
      " [0.5995143 ]\n",
      " [0.6383575 ]\n",
      " [0.71066654]\n",
      " [0.65519947]\n",
      " [0.49987367]\n",
      " [0.70950246]\n",
      " [0.5259646 ]\n",
      " [0.70745724]\n",
      " [0.65777344]\n",
      " [0.7813948 ]\n",
      " [0.76712406]\n",
      " [0.7982409 ]\n",
      " [0.54426056]\n",
      " [0.45208943]\n",
      " [0.6668942 ]\n",
      " [0.6337572 ]\n",
      " [0.748502  ]\n",
      " [0.50802875]\n",
      " [0.630973  ]\n",
      " [0.66301394]\n",
      " [0.7016646 ]\n",
      " [0.65234315]\n",
      " [0.5302921 ]\n",
      " [0.5379583 ]\n",
      " [0.5800197 ]\n",
      " [0.66003895]\n",
      " [0.718305  ]\n",
      " [0.6746428 ]\n",
      " [0.8403368 ]\n",
      " [0.5897699 ]\n",
      " [0.7231038 ]\n",
      " [0.6326604 ]\n",
      " [0.644734  ]\n",
      " [0.6951334 ]\n",
      " [0.46319833]\n",
      " [0.74757975]\n",
      " [0.7058233 ]\n",
      " [0.7070399 ]\n",
      " [0.6164173 ]\n",
      " [0.7564232 ]\n",
      " [0.6626207 ]\n",
      " [0.47808793]\n",
      " [0.6015444 ]\n",
      " [0.55342704]\n",
      " [0.7038389 ]\n",
      " [0.6670233 ]\n",
      " [0.7581924 ]\n",
      " [0.58857405]\n",
      " [0.7921588 ]\n",
      " [0.68960255]\n",
      " [0.7186431 ]\n",
      " [0.62962663]\n",
      " [0.76755905]\n",
      " [0.5696294 ]\n",
      " [0.5882181 ]\n",
      " [0.7643781 ]\n",
      " [0.8160831 ]\n",
      " [0.68156517]\n",
      " [0.75266945]\n",
      " [0.81998086]\n",
      " [0.77633715]\n",
      " [0.6455171 ]\n",
      " [0.6023554 ]\n",
      " [0.8662406 ]\n",
      " [0.6854766 ]\n",
      " [0.7457718 ]\n",
      " [0.55782413]\n",
      " [0.751684  ]\n",
      " [0.62821627]\n",
      " [0.55284584]\n",
      " [0.7362906 ]\n",
      " [0.6180712 ]\n",
      " [0.8239362 ]\n",
      " [0.7627008 ]\n",
      " [0.6061512 ]\n",
      " [0.77212137]\n",
      " [0.59204507]\n",
      " [0.6549157 ]\n",
      " [0.6414988 ]\n",
      " [0.557385  ]\n",
      " [0.6666976 ]\n",
      " [0.7716925 ]\n",
      " [0.8074087 ]\n",
      " [0.67224324]\n",
      " [0.7283503 ]\n",
      " [0.47385865]\n",
      " [0.53508145]\n",
      " [0.729893  ]\n",
      " [0.6548326 ]\n",
      " [0.58306617]\n",
      " [0.5720235 ]\n",
      " [0.8285296 ]\n",
      " [0.70419514]\n",
      " [0.6639515 ]\n",
      " [0.5125364 ]\n",
      " [0.60347646]\n",
      " [0.5197447 ]\n",
      " [0.7660619 ]\n",
      " [0.66224056]\n",
      " [0.5917491 ]\n",
      " [0.538152  ]\n",
      " [0.5201194 ]\n",
      " [0.525016  ]\n",
      " [0.6668214 ]\n",
      " [0.7569914 ]\n",
      " [0.6999985 ]\n",
      " [0.67260295]\n",
      " [0.64715993]\n",
      " [0.7777345 ]\n",
      " [0.515379  ]\n",
      " [0.7896551 ]\n",
      " [0.7669177 ]\n",
      " [0.6107083 ]\n",
      " [0.48747638]\n",
      " [0.6807928 ]\n",
      " [0.6659637 ]\n",
      " [0.7774929 ]\n",
      " [0.67479837]\n",
      " [0.69062877]\n",
      " [0.6711627 ]\n",
      " [0.64709663]\n",
      " [0.50340885]\n",
      " [0.7016535 ]\n",
      " [0.6106312 ]\n",
      " [0.73494077]\n",
      " [0.7050129 ]\n",
      " [0.7731106 ]\n",
      " [0.7840936 ]\n",
      " [0.5067028 ]\n",
      " [0.57572204]\n",
      " [0.40737933]\n",
      " [0.5541808 ]\n",
      " [0.65931433]\n",
      " [0.54778475]\n",
      " [0.5155769 ]\n",
      " [0.73305166]\n",
      " [0.7541013 ]\n",
      " [0.737365  ]\n",
      " [0.6658155 ]\n",
      " [0.646915  ]\n",
      " [0.57278407]\n",
      " [0.8143829 ]\n",
      " [0.608315  ]\n",
      " [0.7672313 ]\n",
      " [0.61898845]\n",
      " [0.742003  ]\n",
      " [0.6414399 ]\n",
      " [0.6144965 ]\n",
      " [0.41692215]\n",
      " [0.5889211 ]\n",
      " [0.5366922 ]\n",
      " [0.7660391 ]\n",
      " [0.60966396]\n",
      " [0.8475181 ]\n",
      " [0.49586022]\n",
      " [0.6284416 ]\n",
      " [0.57611585]\n",
      " [0.60304683]\n",
      " [0.6087317 ]\n",
      " [0.6616329 ]\n",
      " [0.7015015 ]\n",
      " [0.77949023]\n",
      " [0.49278742]\n",
      " [0.77356607]\n",
      " [0.6244697 ]\n",
      " [0.68199486]\n",
      " [0.77628016]\n",
      " [0.63318384]\n",
      " [0.7096591 ]\n",
      " [0.5296211 ]\n",
      " [0.701818  ]\n",
      " [0.48745382]\n",
      " [0.663607  ]\n",
      " [0.70184404]\n",
      " [0.7292913 ]\n",
      " [0.64012396]\n",
      " [0.5009906 ]\n",
      " [0.7817744 ]\n",
      " [0.71650684]\n",
      " [0.65505177]\n",
      " [0.7346605 ]\n",
      " [0.6170633 ]\n",
      " [0.6192005 ]\n",
      " [0.6369005 ]\n",
      " [0.76859987]\n",
      " [0.6386927 ]\n",
      " [0.5984709 ]\n",
      " [0.7559648 ]\n",
      " [0.540955  ]\n",
      " [0.7314824 ]\n",
      " [0.71597135]\n",
      " [0.79623425]\n",
      " [0.6293471 ]\n",
      " [0.64612556]\n",
      " [0.5647708 ]\n",
      " [0.54605997]\n",
      " [0.61492383]\n",
      " [0.7457528 ]\n",
      " [0.62620366]\n",
      " [0.5998529 ]\n",
      " [0.55096143]\n",
      " [0.5699232 ]\n",
      " [0.65223444]\n",
      " [0.80787534]\n",
      " [0.7695298 ]\n",
      " [0.6277379 ]\n",
      " [0.8161271 ]\n",
      " [0.70197254]\n",
      " [0.7434641 ]\n",
      " [0.5879134 ]\n",
      " [0.5382402 ]\n",
      " [0.674302  ]\n",
      " [0.5413727 ]\n",
      " [0.56303567]\n",
      " [0.6412516 ]\n",
      " [0.7181965 ]\n",
      " [0.4228292 ]\n",
      " [0.6233197 ]\n",
      " [0.5035005 ]\n",
      " [0.49391684]\n",
      " [0.74282706]\n",
      " [0.82002604]\n",
      " [0.6620945 ]\n",
      " [0.7211913 ]\n",
      " [0.5879334 ]\n",
      " [0.79899013]\n",
      " [0.83537877]\n",
      " [0.6326832 ]\n",
      " [0.5895242 ]\n",
      " [0.58707273]\n",
      " [0.7326237 ]\n",
      " [0.42581385]\n",
      " [0.5259263 ]\n",
      " [0.59337425]\n",
      " [0.5052548 ]\n",
      " [0.49632868]\n",
      " [0.56721514]\n",
      " [0.79067445]\n",
      " [0.4749719 ]\n",
      " [0.7703705 ]\n",
      " [0.41273665]], shape=(407, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.         0.29777778 0.         ... 0.         0.         0.        ]\n",
      " [1.         0.52444444 1.         ... 0.         0.         0.        ]\n",
      " [0.         0.16       0.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.         0.45777778 0.         ... 0.         0.         1.        ]\n",
      " [1.         0.89777778 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.31555556 0.         ... 1.         0.         0.        ]], shape=(407, 77), dtype=float64)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "data_x_training_train = training_scaler.fit_transform(data_x_training_bf_scaling[dict_train[0]])\n",
    "data_x_training_test = training_scaler.transform(data_x_training_bf_scaling[dict_test[0]])\n",
    "\n",
    "model = tf.keras.models.load_model('./ANN_ASAS20_50_1_3e-05_111_1.h5')\n",
    "\n",
    "img_array = tf.convert_to_tensor(data_x_training_train)\n",
    "last_conv_layer_model = keras.Model(model.inputs, model.output)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "    tape.watch(last_conv_layer_output)\n",
    "\n",
    "print(last_conv_layer_output)\n",
    "print(img_array)\n",
    "grads = tape.gradient(last_conv_layer_output, img_array)\n",
    "print(grads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
